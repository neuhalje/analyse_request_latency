{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "Analyse (a custom formated) http-request log for request duration.\n",
    "\n",
    "Start with `jupyter notebook`.\n",
    "\n",
    "\n",
    "## Example\n",
    "\n",
    "![All requests](README.inc/all_requests.png)\n",
    "\n",
    "![Just operation G](README.inc/operation_g_requests.png)\n",
    "\n",
    "## Data format\n",
    "\n",
    "The example dataset is split into the following columns\n",
    "\n",
    "| Name | format | description |\n",
    "|---|---|---|\n",
    "| Timestamp  | timestamp  | Occurence of the request  |\n",
    "| URL  | string | URL of the request (ignored!)  |\n",
    "| command  | string  | The command executed. This is the grouping criteria for analysis.  |\n",
    "| duration_s  | int  | Duration (in seconds) of the request.  |\n",
    "\n",
    "```csv\n",
    "14/Jan/2019:03:46:03 /example/url operation_G 0\n",
    "14/Jan/2019:03:46:07 /example/url operation_G 0\n",
    "14/Jan/2019:03:46:07 /example/url operation_G 2\n",
    "14/Jan/2019:03:46:08 /example/url operation_G 0\n",
    "14/Jan/2019:03:46:09 /example/url operation_G 0\n",
    "14/Jan/2019:03:46:10 /example/url operation_B 5\n",
    "14/Jan/2019:03:46:19 /example/url operation_A 0\n",
    "14/Jan/2019:03:46:19 /example/url operation_F 90\n",
    "14/Jan/2019:03:46:20 /example/url operation_E 9\n",
    "14/Jan/2019:03:46:24 /example/url operation_F 0\n",
    "```\n",
    "\n",
    "## Contributing\n",
    "\n",
    "I am hosted at [GitHub](https://github.com/neuhalje/analyse_request_latency)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None: all, any other value: just this operation\n",
    "COMMAND_FILTER=None\n",
    "#COMMAND_FILTER=\"operation_G\"\n",
    "\n",
    "\n",
    "# None: all\n",
    "# Take a sample for visualisation\n",
    "MAX_ELEMENT_COUNT=None   # I strongly advise against more than 100k elements (performance)\n",
    "\n",
    "MAX_ELEMENT_COUNT=10_000\n",
    "\n",
    "# set any outliers that take longer than `PERCENTILE_LIMIT` percent of the calls to this ceiling\n",
    "# this removes outliers. Will never be higher than SECONDS_LIMIT\n",
    "PERCENTILE_LIMIT=0.999\n",
    "SECONDS_LIMIT=60\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-offset-aliases\n",
    "#ROUND_TO=\"15min\"\n",
    "#ROUND_TO=\"6H\"\n",
    "ROUND_TO=\"1min\"\n",
    "\n",
    "_DATASET_SMALL=\"example_dataset.txt\"\n",
    "_DATASET_LARGE=\"combined-sorted.txt\"\n",
    "\n",
    "DATASET=_DATASET_SMALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install scipy plotly pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "#Always run this the command before at the start of notebook (for Plotly)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def configure_figure_size():\n",
    "    matplotlib.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "//  This is unsupported but increases the size of the output. Needed to really see the heatmaps\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET, sep=\" \")\n",
    "df.columns = ['ts', 'url', 'command', 'duration_s']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial datase information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.command.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration_s.describe(percentiles=[.25, .5, .75, .9, .95, .99, .999,.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration_s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the dataset, take a sampling (for faster processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMAND_FILTER:\n",
    "    df = df.query(\"command == @COMMAND_FILTER\")\n",
    "\n",
    "if MAX_ELEMENT_COUNT:\n",
    "     df = df.sample(n=min(MAX_ELEMENT_COUNT, len(df.index)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data\n",
    "\n",
    "You can customize the format of the timestamp here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df.ts,format=\"%d/%b/%Y:%H:%M:%S\")\n",
    "\n",
    "# put all requests in bins (e.g. 15min bins)\n",
    "df['approx_ts'] = df['timestamp'].dt.round(ROUND_TO)  \n",
    "df.sort_values(by='timestamp', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip outliers\n",
    "\n",
    "Two bounds are put on the lateny:\n",
    "* an absolute bound of `SECONDS_LIMIT` seconds\n",
    "* the `PERCENTILE_LIMIT`  (e.g. 0.999) which is calculated from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_dataset(df):\n",
    "    q = df.duration_s.quantile(q=PERCENTILE_LIMIT)\n",
    "    latency_clipped_at = min(SECONDS_LIMIT,q)\n",
    "    df.duration_s.clip_upper(latency_clipped_at,inplace=True)\n",
    "    return latency_clipped_at\n",
    "\n",
    "latency_clipped_at = clip_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration_s.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put time of measurements buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = 1\n",
    "grouped = df.groupby(['approx_ts','duration_s'], as_index=False)\n",
    "aggregated = grouped['count'].agg(np.size)\n",
    "aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.timestamp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the distribution of  latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_of_duration_s(df):\n",
    "    configure_figure_size()\n",
    "    sns.distplot(df.duration_s, kde=False)\n",
    "    \n",
    "distribution_of_duration_s(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lateny_log():\n",
    "\n",
    "    configure_figure_size()\n",
    "\n",
    "    # Seaborn converts plotting inputs to numpy arrays\n",
    "    x = np.asarray(df.timestamp)\n",
    "    y = np.asarray(df.duration_s)\n",
    "    plt.yscale('log')\n",
    "    plt.plot_date(x, y)\n",
    "\n",
    "plot_lateny_log()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latency Heatmap\n",
    "\n",
    "Show latency as a heatmap with time on the x-axis, latency on the y-axis and color frequency of measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def aggregate_for_heatmap(df):\n",
    "    grouped = df.groupby(['approx_ts','duration_s'], as_index=False)\n",
    "    aggregated = grouped['count'].agg(np.size)\n",
    "    return aggregated\n",
    "    \n",
    "def plot_latency_heatmap(aggregated, command):\n",
    "    call_count = aggregated['count'].sum()\n",
    "    if command:\n",
    "        title = f'Latency of {call_count:_} \"{command}\" calls'\n",
    "    else:\n",
    "        # not filtered\n",
    "        title = f'Latency of {call_count:_} calls'\n",
    "        \n",
    "                     \n",
    "    trace = dict(\n",
    "        z=[aggregated['approx_ts'],aggregated['duration_s'],aggregated['count']], \n",
    "        type=\"heatmap\", \n",
    "        zmin=1, \n",
    "        zmax=60, \n",
    "        colorscale='Viridis')\n",
    "    \n",
    "    layout= go.Layout(\n",
    "            title= title,\n",
    "            hovermode= 'closest',\n",
    "            xaxis= dict(\n",
    "                title= 'Timestamp',\n",
    "                ticklen= 5,\n",
    "                zeroline= False,\n",
    "                gridwidth= 2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title= f'Latency in [s] (capped at {latency_clipped_at})',\n",
    "            ticklen= 5,\n",
    "            gridwidth= 2,\n",
    "        ),\n",
    "        showlegend= False\n",
    "    )\n",
    "\n",
    "    text_labels = [ f\"\"\"{when} - {count:_} call(s) w. {latency}s latency\"\"\"  \n",
    "                   for when, latency,count in  \n",
    "                       zip(aggregated['approx_ts'],\n",
    "                           aggregated['duration_s'],\n",
    "                           aggregated['count'])\n",
    "                  ]\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x = aggregated['approx_ts'],\n",
    "        y = aggregated['duration_s'],\n",
    "        text  = text_labels,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color = aggregated['count'],\n",
    "            colorscale='Hot',\n",
    "            showscale=True,\n",
    "            symbol=\"square\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    data = [trace1]\n",
    "    fig= go.Figure(data=data, layout=layout)\n",
    "\n",
    "    iplot(fig)\n",
    "\n",
    "plot_latency_heatmap(aggregate_for_heatmap(df), command = None)    \n",
    "for command in df['command'].unique():\n",
    "    filtered_df = df.query(\"command == @command\")\n",
    "    filtered_aggregate = aggregate_for_heatmap(filtered_df)\n",
    "    plot_latency_heatmap(filtered_aggregate, command)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
